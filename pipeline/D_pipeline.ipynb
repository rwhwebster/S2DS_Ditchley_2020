{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize graph database\n",
    "\n",
    "Databse must be active, this can be done in the neo4j desktop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Set up working directory\n",
    "# The working directory should reflect the structure of the Github repository https://github.com/S2DSLondon/Aug20_Ditchley\n",
    "sys.path.insert(1, '/Users/adam/S2DS/GitHub/Aug20_Ditchley')\n",
    "from src.graph_database import graphdb as gdb\n",
    "\n",
    "#Set the keyword of interest\n",
    "keyword = 'cybersecurity'\n",
    "\n",
    "# load / declare the database\n",
    "graph = gdb.get_graph(new_graph = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neo4j import files need to be in a specific folder, however, the csv files saved above are in a different folder, to get around this problem on Windows machines it is possible to create a shortcut between the two folders, on linux/mac one can create a symbolic link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files into the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in journalists\n",
    "\n",
    "Journalists exist as (Person) nodes on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in user information and drawing (Person) nodes\n"
     ]
    }
   ],
   "source": [
    "# load in user information\n",
    "print('Loading in user information and drawing (Person) nodes')\n",
    "fn_users = 'processed/'+keyword+'_user_profiles.csv'\n",
    "gdb.load_users(fn_users ,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in journalists' friends\n",
    "\n",
    "Friends exist as (Person) nodes on the graph. Journalists connect to friends by [FOLLOWS] edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in friends info and drawing [FOLLOWS] edges\n"
     ]
    }
   ],
   "source": [
    "# load in friend information\n",
    "print('Loading in friends info and drawing [FOLLOWS] edges')\n",
    "fn_friends = 'processed/'+keyword+'_journalist_friends.csv'\n",
    "gdb.load_friends(fn_friends,graph,new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload profile information of friends\n",
    "fn = 'processed/'+keyword+'_user_friends_profiles.csv'\n",
    "gdb.load_existing_users(fn,graph) \n",
    "#gdb.load_existing_users('processed/'+keyword+'_all_profiles.csv',graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in tweets\n",
    "\n",
    "Tweets exist as (Tweet) nodes on the graph. They are connected to the users who tweeted them via [POSTS] edges. If they mention someone in the graph then they connect to that user via a [MENTIONS] edge. If the tweet is a reply to another tweet in the graph then it is connected to that tweet via a [REPLIES_TO] edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in tweets and drawing (Tweet) nodes\n"
     ]
    }
   ],
   "source": [
    "# load in tweet information from twint\n",
    "print('Loading in tweets and drawing (Tweet) nodes')\n",
    "fn_tweets = 'processed/'+keyword+'_standard_tweets_twint.csv'\n",
    "gdb.load_tweets(fn_tweets ,graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in tweets and drawing (Tweet) nodes\n"
     ]
    }
   ],
   "source": [
    "# load in tweet information from API\n",
    "print('Loading in tweets and drawing (Tweet) nodes')\n",
    "fn_tweets = 'processed/'+keyword+'_standard_tweets_api.csv'\n",
    "gdb.load_tweets(fn_tweets ,graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing [POSTS] edges\n"
     ]
    }
   ],
   "source": [
    "# draw edges between users and their tweets\n",
    "print('Drawing [POSTS] edges')\n",
    "gdb.get_posts(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in mentions and drawing [MENTIONS] edges\n"
     ]
    }
   ],
   "source": [
    "# load in mentions information\n",
    "print('Loading in mentions and drawing [MENTIONS] edges')\n",
    "fn_mentions = 'processed/'+keyword+'_mentions_twint.csv'\n",
    "gdb.load_mentions(fn_mentions,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From MENTIONS information we can draw [TALKS_ABOUT] edges between users. These have a weight equal to the number of times one user mentions another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count mentions to draw [TALKS_ABOUT] edges\n",
    "gdb.get_talk_about_edges(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in topics\n",
    "\n",
    "If we have some results from the topic modelling then we can include them in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file containing a list of users and their associated topics\n",
    "fn_topics = 'processed/user_name_topics_summed_10.csv'\n",
    "\n",
    "# minimum threshhold to link a user with a topic\n",
    "threshhold = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in topics as (Topic) nodes and draw [TWEETS_ABOUT] edges between topics and users who pass a certain threshhold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb.load_topics(fn_topics,graph,threshhold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "\n",
    "Celebrities and public figures may have millions of followers but only a handful of friends. Conversely, inactive or irregular Twitter users may have very few friends and followers. These profiles, who are not of interest to us, are often outliers in the statistical distribution of friends and followers.\n",
    "\n",
    "### Friends & followers\n",
    "\n",
    "Assume friends and followers are lognormally distributed, calculate the chi squared of each user and remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in user metrics from file, alternatively one could download them from the graph\n",
    "user_profiles = pd.read_csv('../data/processed/'+keyword+'_user_profiles.csv' )\n",
    "user_friends_profiles = pd.read_csv('../data/processed/'+keyword+'_user_friends_profiles.csv' )\n",
    "users_df = pd.concat([user_profiles,user_friends_profiles])\n",
    "users_df = users_df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the chi squared for each user\n",
    "no_loners = gdb.get_chi2(users_df)\n",
    "\n",
    "#We can then classify each user as an inlier or outlier based on their chisquared\n",
    "chi2_lim = 6.18\n",
    "inliers = no_loners[no_loners['chi2']<chi2_lim]\n",
    "outliers = no_loners[no_loners['chi2']>chi2_lim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add chi2 as a property to each node\n",
    "gdb.add_property('chi2',no_loners,graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excise outliers from database\n",
    "gdb.excise_outliers(outliers['screen_name'],graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H-index\n",
    "\n",
    "Profiles with a very high H-index are often high profile generalist accounts. Profiles with an H-index of zero or a few do not illicit much interaction at all from other twitter users and so are not interesting to us. Again, assuming that the H-index is lognormally distributed we can calculate each user's position in the distribution and excise any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data file containing H-index information\n",
    "h_index = pd.read_csv('../data/processed/cybersecurity_h_index_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add H-index as a property on the graph\n",
    "# some entries have an H-index of -1, which is meaningless\n",
    "h_index = h_index[h_index['h_index_like_retweets']>0]\n",
    "gdb.add_property('h_index_like_retweets',h_index,graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate chi2 for the H-index distribution\n",
    "with_h_chi2 = gdb.get_chi2_H_index(h_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of outliers\n",
    "chi2_lim = 4.0\n",
    "black_list = with_h_chi2[with_h_chi2['chi2']>chi2_lim]['screen_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1             duykham_\n",
       "12      richarddawkins\n",
       "22         nilerodgers\n",
       "67            v3_co_uk\n",
       "79         chromiumdev\n",
       "             ...      \n",
       "1562       _jakubjanda\n",
       "1582         zraadsato\n",
       "1594     kennedy__news\n",
       "1603    grinfosecurity\n",
       "1705    lawrenceabrams\n",
       "Name: screen_name, Length: 103, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excise outliers from the graph\n",
    "gdb.excise_outliers(black_list,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running page rank\n"
     ]
    }
   ],
   "source": [
    "# run Page rank using follower edges\n",
    "print('running page rank')\n",
    "nodelist = ['Person']\n",
    "edgelist = ['FOLLOWS','TALKS_ABOUT']\n",
    "page_rank = gdb.run_pagerank(nodelist,edgelist,graph,new_native_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       screen_name      rank n_followers\n",
      "0  securitycharlie  0.150809       10827\n",
      "1       fbnewsroom  0.150809      127582\n",
      "2         awscloud  0.150809     1843461\n",
      "3        fisher85m  0.150809       87935\n",
      "4          gcluley  0.150809       97984\n",
      "5   blackhatevents  0.150677      280103\n",
      "6        albinowax  0.150677       30239\n",
      "7        dailyswig  0.150677        5040\n",
      "8        joelgmsec  0.150677         910\n",
      "9     bsideslondon  0.150663        8076\n"
     ]
    }
   ],
   "source": [
    "print(page_rank[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to run the neo4j graph algorithms in such a way that they automatically write new properties to the nodes. However, here we shall write these properties manually using our add_properties function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb.add_property('rank',page_rank,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Graph Boosting\n",
    "\n",
    "Attempting to find all the friends of friends may result in downloading hundreds of thousands or millions of profiles. The network gets exponentially bigger at each level of abstraction. We can avoid this by selecting a random sample of users in our database and seeing if they are following anyone else in our database. We can weight this random selection by, for example, their previously determined rank or the number of friends or followers they have. By repeating this process several times we can build complexity into our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:Cannot connect to host twitter.com:443 ssl:True [nodename nor servname provided, or not known]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boost iteration  1\n",
      "Attempt #1 to get friends of @rawanssa18\n",
      "Attempt #1 to get friends of @udit_thakkur\n",
      "Attempt #1 to get friends of @kevinjones_hc"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py\", line 97, in _event_pipe\n",
      "AttributeError: '_thread._local' object has no attribute 'event_pipe'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/threading.py\", line 864, in run\n",
      "  File \"/Users/adam/S2DS/GitHub/Aug20_Ditchley/src/data/twint_tools.py\", line 49, in _get_friends\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py\", line 376, in write\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py\", line 203, in schedule\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py\", line 101, in _event_pipe\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/zmq/sugar/context.py\", line 146, in socket\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 285, in zmq.backend.cython.socket.Socket.__cinit__\n",
      "zmq.error.ZMQError: Too many open files\n",
      "Unhandled exception in thread started by <bound method Thread._bootstrap of <Thread(Thread-35, started 123151839346688)>>\n",
      "Exception in thread Thread-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/run.py\", line 215, in run\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/events.py\", line 694, in get_event_loop\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/events.py\", line 602, in get_event_loop\n",
      "RuntimeError: There is no current event loop in thread 'Thread-36'.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/threading.py\", line 864, in run\n",
      "  File \"/Users/adam/S2DS/GitHub/Aug20_Ditchley/src/data/twint_tools.py\", line 57, in _get_friends\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/run.py\", line 265, in Following\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/run.py\", line 218, in run\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/events.py\", line 704, in new_event_loop\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/events.py\", line 617, in new_event_loop\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/unix_events.py\", line 56, in __init__\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/selector_events.py\", line 67, in __init__\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/selector_events.py\", line 129, in _make_self_pipe\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/unix_events.py\", line 60, in _socketpair\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/socket.py\", line 488, in socketpair\n",
      "OSError: [Errno 24] Too many open files\n",
      "\n",
      "Exception ignored in: <bound method BaseEventLoop.__del__ of <_UnixSelectorEventLoop running=False closed=False debug=False>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/base_events.py\", line 512, in __del__\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/unix_events.py\", line 63, in close\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/selector_events.py\", line 110, in close\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/selector_events.py\", line 120, in _close_self_pipe\n",
      "AttributeError: '_UnixSelectorEventLoop' object has no attribute '_ssock'\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "--- Logging error ---\n",
      "Error in sys.excepthook:\n",
      "Traceback (most recent call last):\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "\n",
      "Original exception was:\n",
      "Traceback (most recent call last):\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "Exception in thread Thread-34:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/aiohttp/connector.py\", line 967, in _create_direct_connection\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/futures.py\", line 327, in __iter__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/tasks.py\", line 250, in _wakeup\n",
      "    future.result()\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/futures.py\", line 243, in result\n",
      "    raise self._exception\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/tasks.py\", line 182, in _step\n",
      "    result = coro.throw(exc)\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/aiohttp/connector.py\", line 830, in _resolve_host\n",
      "    self._resolver.resolve(host, port, family=self._family)\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/aiohttp/resolver.py\", line 30, in resolve\n",
      "    host, port, type=socket.SOCK_STREAM, family=family)\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/futures.py\", line 327, in __iter__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/tasks.py\", line 250, in _wakeup\n",
      "    future.result()\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/futures.py\", line 243, in result\n",
      "    raise self._exception\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/concurrent/futures/thread.py\", line 56, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/socket.py\", line 745, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "socket.gaierror: [Errno 8] nodename nor servname provided, or not known\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/threading.py\", line 864, in run\n",
      "  File \"/Users/adam/S2DS/GitHub/Aug20_Ditchley/src/data/twint_tools.py\", line 57, in _get_friends\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/run.py\", line 265, in Following\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/run.py\", line 226, in run\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/nest_asyncio.py\", line 95, in run_until_complete\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/tasks.py\", line 182, in _step\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/run.py\", line 154, in main\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/tasks.py\", line 250, in _wakeup\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/asyncio/tasks.py\", line 182, in _step\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/run.py\", line 190, in run\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/run.py\", line 109, in follow\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/run.py\", line 45, in Feed\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/get.py\", line 119, in RequestUrl\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/get.py\", line 143, in Request\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/twint/get.py\", line 148, in Response\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/aiohttp/client.py\", line 1012, in __aenter__\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/aiohttp/client.py\", line 483, in _request\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/aiohttp/connector.py\", line 523, in connect\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/aiohttp/connector.py\", line 859, in _create_connection\n",
      "  File \"/Users/adam/anaconda3/lib/python3.6/site-packages/aiohttp/connector.py\", line 971, in _create_direct_connection\n",
      "aiohttp.client_exceptions.ClientConnectorError: Cannot connect to host mobile.twitter.com:443 ssl:True [nodename nor servname provided, or not known]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run boosting\n",
    "\n",
    "# number of boosting iterations\n",
    "niter = 5\n",
    "\n",
    "# number of samples to be drawn on each iteration\n",
    "nsample = 5\n",
    "\n",
    "# field(s) to be weighted \n",
    "fields = ['rank']\n",
    "\n",
    "# strength of weights (-ve to downweight)\n",
    "exponents = [2]\n",
    "\n",
    "# arguments for twint\n",
    "kwargs = {'n_retries':2,\n",
    "         'suppress':False}\n",
    "\n",
    "# package pagerank parameters into tuple\n",
    "pagerank_params = nodelist, edgelist, graph\n",
    "\n",
    "# run boosting, now would be a good time to make a cup of tea\n",
    "gdb.boost_graph(niter,nsample,fields,exponents,pagerank_params,keyword,kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter graph by keywords\n",
    "\n",
    "Look for keywords in the bio and screen name of friends, filter users who have these keywords.\n",
    "\n",
    "This is a brute force approach to identifying users associated with a topic. It can used in conjunction with or instead of the topic modelling. For example, one may select the list of key words based on analysing hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733\n"
     ]
    }
   ],
   "source": [
    "keywords = ['tech','security','artificial','machine', 'cyber', 'computer','code','hack']\n",
    "not_techies = gdb.filter_users_by_keywords(keywords,graph,without=True)\n",
    "print(len(not_techies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excise uninteresting profiles\n",
    "gdb.excise_outliers(not_techies['screen name'],graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by topic\n",
    "\n",
    "Use the results of the topic modelling to get a list a users who tweet about a given topic regularly. Users who don't regularly tweet about this topic can be excised from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of users who DO talk about a topic\n",
    "topic = 'Cybersecurity'\n",
    "topical = gdb.filter_by_topic(topic,graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      screen_name\n",
      "0      biicscyber\n",
      "1      cybergovau\n",
      "2     marynchaney\n",
      "3      dm_janosek\n",
      "4  hannanhaseeb11\n",
      "5     digitalamli\n",
      "6    scottrrodman\n",
      "7        esentire\n",
      "8   uncommonmercs\n",
      "9      scmagazine\n"
     ]
    }
   ],
   "source": [
    "# have a look at a few entries\n",
    "print(topical[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of users who DON'T talk about this topic\n",
    "untopical = users_df[~users_df['screen_name'].isin(topical['screen_name'])]['screen_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       _lucyingham\n",
      "1     jesscahaworth\n",
      "2      ad_nauseum74\n",
      "3    yahtzeecroshaw\n",
      "4         artbymoga\n",
      "5       rokitskates\n",
      "6       gingertotty\n",
      "7     oddlypieasing\n",
      "8           j0ne_s_\n",
      "9       maddiestone\n",
      "Name: screen_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# have a look at a few entries\n",
    "print(untopical[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excise untopical users\n",
    "gdb.excise_outliers(untopical,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run page rank again to get ranking within topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running page rank\n"
     ]
    }
   ],
   "source": [
    "# run Page rank using follower edges\n",
    "print('running page rank')\n",
    "nodelist = ['Person']\n",
    "edgelist = ['FOLLOWS']\n",
    "page_rank = gdb.run_pagerank(nodelist,edgelist,graph,new_native_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>rank</th>\n",
       "      <th>n_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>markbward</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cybersec_feeds</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>infoblox</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emil0xa</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>icscert</td>\n",
       "      <td>0.15</td>\n",
       "      <td>11327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scmagazine</td>\n",
       "      <td>0.15</td>\n",
       "      <td>116504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>darktrace</td>\n",
       "      <td>0.15</td>\n",
       "      <td>11795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>raj_samani</td>\n",
       "      <td>0.15</td>\n",
       "      <td>12052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>uscert_gov</td>\n",
       "      <td>0.15</td>\n",
       "      <td>121942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nca_uk</td>\n",
       "      <td>0.15</td>\n",
       "      <td>122233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>j0ne_s_</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cyber_nb</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eskenzipr_rohit</td>\n",
       "      <td>0.15</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cybersecuritysf</td>\n",
       "      <td>0.15</td>\n",
       "      <td>12622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xylafoxlin</td>\n",
       "      <td>0.15</td>\n",
       "      <td>12821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cyberukevents</td>\n",
       "      <td>0.15</td>\n",
       "      <td>12933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>paraneonu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>yahtzeecroshaw</td>\n",
       "      <td>0.15</td>\n",
       "      <td>129904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>packetcop</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>neirajones</td>\n",
       "      <td>0.15</td>\n",
       "      <td>13208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        screen_name  rank n_followers\n",
       "0         markbward  0.15        1049\n",
       "1    cybersec_feeds  0.15       10565\n",
       "2          infoblox  0.15       10709\n",
       "3           emil0xa  0.15        1102\n",
       "4           icscert  0.15       11327\n",
       "5        scmagazine  0.15      116504\n",
       "6         darktrace  0.15       11795\n",
       "7        raj_samani  0.15       12052\n",
       "8        uscert_gov  0.15      121942\n",
       "9            nca_uk  0.15      122233\n",
       "10          j0ne_s_  0.15        1240\n",
       "11         cyber_nb  0.15        1259\n",
       "12  eskenzipr_rohit  0.15         126\n",
       "13  cybersecuritysf  0.15       12622\n",
       "14       xylafoxlin  0.15       12821\n",
       "15    cyberukevents  0.15       12933\n",
       "16        paraneonu  0.15        1298\n",
       "17   yahtzeecroshaw  0.15      129904\n",
       "18        packetcop  0.15        1318\n",
       "19       neirajones  0.15       13208"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_rank[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
