{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ditchley S2DS project August 2020 - Pipeline D\n",
    "\n",
    "## Team: Adam Hawken, Luca Lamoni, Elizabeth Nicholson, Robert Webster\n",
    "\n",
    "This notebook (D_pipeline) will be dedicated to:\n",
    "D1: Initializing the Neo4j Graph Database \n",
    "D2: Importing files into the Neo4j Graph Database\n",
    "D3: Remove statistical outliers\n",
    "D4: Graph Boosting\n",
    "D5: Filter by Topic and keyword\n",
    "\n",
    "\n",
    "## Section D.1: Initialize graph database\n",
    "\n",
    "Databse must be active, this can be done in the neo4j desktop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.1: Open database and set keyword "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Set up working directory\n",
    "# The working directory should reflect the structure of the Github repository https://github.com/S2DSLondon/Aug20_Ditchley\n",
    "sys.path.insert(1, '/Users/adam/S2DS/GitHub/Aug20_Ditchley')\n",
    "from src.graph_database import graphdb as gdb\n",
    "\n",
    "#Set the keyword of interest\n",
    "keyword = 'cybersecurity'\n",
    "\n",
    "# load / declare the database\n",
    "graph = gdb.get_graph(new_graph = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neo4j import files need to be in a specific folder, however, the csv files saved above are in a different folder, to get around this problem on Windows machines it is possible to create a shortcut between the two folders, on linux/mac one can create a symbolic link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.2 Load files into the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.2.1 Load in journalists\n",
    "\n",
    "Journalists exist as (Person) nodes on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in user information and drawing (Person) nodes\n"
     ]
    }
   ],
   "source": [
    "# load in user information\n",
    "print('Loading in user information and drawing (Person) nodes')\n",
    "fn_users = 'processed/'+keyword+'_user_profiles.csv'\n",
    "gdb.load_users(fn_users ,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.2.2 Load in journalists' friends\n",
    "\n",
    "Friends exist as (Person) nodes on the graph. Journalists connect to friends by [FOLLOWS] edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in friends info and drawing [FOLLOWS] edges\n"
     ]
    }
   ],
   "source": [
    "# load in friend information\n",
    "print('Loading in friends info and drawing [FOLLOWS] edges')\n",
    "fn_friends = 'processed/'+keyword+'_journalist_friends.csv'\n",
    "gdb.load_friends(fn_friends,graph,new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload profile information of friends\n",
    "fn = 'processed/'+keyword+'_user_friends_profiles.csv'\n",
    "gdb.load_existing_users(fn,graph) \n",
    "#gdb.load_existing_users('processed/'+keyword+'_all_profiles.csv',graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.2.3 Load in tweets\n",
    "\n",
    "Tweets exist as (Tweet) nodes on the graph. They are connected to the users who tweeted them via [POSTS] edges. If they mention someone in the graph then they connect to that user via a [MENTIONS] edge. If the tweet is a reply to another tweet in the graph then it is connected to that tweet via a [REPLIES_TO] edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in tweets and drawing (Tweet) nodes\n"
     ]
    }
   ],
   "source": [
    "# load in tweet information from twint\n",
    "print('Loading in tweets and drawing (Tweet) nodes')\n",
    "fn_tweets = 'processed/'+keyword+'_standard_tweets_twint.csv'\n",
    "gdb.load_tweets(fn_tweets ,graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in tweets and drawing (Tweet) nodes\n"
     ]
    }
   ],
   "source": [
    "# load in tweet information from API\n",
    "print('Loading in tweets and drawing (Tweet) nodes')\n",
    "fn_tweets = 'processed/'+keyword+'_standard_tweets_api.csv'\n",
    "gdb.load_tweets(fn_tweets ,graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing [POSTS] edges\n"
     ]
    }
   ],
   "source": [
    "# draw edges between users and their tweets\n",
    "print('Drawing [POSTS] edges')\n",
    "gdb.get_posts(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in mentions and drawing [MENTIONS] edges\n"
     ]
    }
   ],
   "source": [
    "# load in mentions information\n",
    "print('Loading in mentions and drawing [MENTIONS] edges')\n",
    "fn_mentions = 'processed/'+keyword+'_mentions_twint.csv'\n",
    "gdb.load_mentions(fn_mentions,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From MENTIONS information we can draw [TALKS_ABOUT] edges between users. These have a weight equal to the number of times one user mentions another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count mentions to draw [TALKS_ABOUT] edges\n",
    "gdb.get_talk_about_edges(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.2.4 Load in topics\n",
    "\n",
    "If we have some results from the topic modelling then we can include them in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file containing a list of users and their associated topics\n",
    "fn_topics = 'processed/user_name_topics_summed_10.csv'\n",
    "\n",
    "# minimum threshhold to link a user with a topic\n",
    "threshhold = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in topics as (Topic) nodes and draw [TWEETS_ABOUT] edges between topics and users who pass a certain threshhold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb.load_topics(fn_topics,graph,threshhold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.3 Remove statistical outliers\n",
    "\n",
    "Celebrities and public figures may have millions of followers but only a handful of friends. Conversely, inactive or irregular Twitter users may have very few friends and followers. These profiles, who are not of interest to us, are often outliers in the statistical distribution of friends and followers.\n",
    "\n",
    "### D.3.1 Friends & followers\n",
    "\n",
    "Assume friends and followers are lognormally distributed, calculate the chi squared of each user and remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in user metrics from file, alternatively one could download them from the graph\n",
    "user_profiles = pd.read_csv('../data/processed/'+keyword+'_user_profiles.csv' )\n",
    "user_friends_profiles = pd.read_csv('../data/processed/'+keyword+'_user_friends_profiles.csv' )\n",
    "users_df = pd.concat([user_profiles,user_friends_profiles])\n",
    "users_df = users_df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the chi squared for each user\n",
    "no_loners = gdb.get_chi2(users_df)\n",
    "\n",
    "#We can then classify each user as an inlier or outlier based on their chisquared\n",
    "chi2_lim = 6.18\n",
    "inliers = no_loners[no_loners['chi2']<chi2_lim]\n",
    "outliers = no_loners[no_loners['chi2']>chi2_lim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add chi2 as a property to each node\n",
    "gdb.add_property('chi2',no_loners,graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excise outliers from database\n",
    "gdb.excise_outliers(outliers['screen_name'],graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.3.2 H-index\n",
    "\n",
    "Profiles with a very high H-index are often high profile generalist accounts. Profiles with an H-index of zero or a few do not illicit much interaction at all from other twitter users and so are not interesting to us. Again, assuming that the H-index is lognormally distributed we can calculate each user's position in the distribution and excise any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data file containing H-index information\n",
    "h_index = pd.read_csv('../data/processed/cybersecurity_h_index_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add H-index as a property on the graph\n",
    "# some entries have an H-index of -1, which is meaningless\n",
    "h_index = h_index[h_index['h_index_like_retweets']>0]\n",
    "gdb.add_property('h_index_like_retweets',h_index,graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate chi2 for the H-index distribution\n",
    "with_h_chi2 = gdb.get_chi2_H_index(h_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of outliers\n",
    "chi2_lim = 4.0\n",
    "black_list = with_h_chi2[with_h_chi2['chi2']>chi2_lim]['screen_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excise outliers from the graph\n",
    "gdb.excise_outliers(black_list,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.4 Graph Boosting and Graph Algorithms \n",
    "\n",
    "### D.4.1 Run Page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Page rank using follower edges\n",
    "print('running page rank')\n",
    "nodelist = ['Person']\n",
    "edgelist = ['FOLLOWS','TALKS_ABOUT']\n",
    "page_rank = gdb.run_pagerank(nodelist,edgelist,graph,new_native_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_rank[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to run the neo4j graph algorithms in such a way that they automatically write new properties to the nodes. However, here we shall write these properties manually using our add_properties function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb.add_property('rank',page_rank,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.4.2 Monte Carlo Graph Boosting\n",
    "\n",
    "Attempting to find all the friends of friends may result in downloading hundreds of thousands or millions of profiles. The network gets exponentially bigger at each level of abstraction. We can avoid this by selecting a random sample of users in our database and seeing if they are following anyone else in our database. We can weight this random selection by, for example, their previously determined rank or the number of friends or followers they have. By repeating this process several times we can build complexity into our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run boosting\n",
    "\n",
    "# number of boosting iterations\n",
    "niter = 5\n",
    "\n",
    "# number of samples to be drawn on each iteration\n",
    "nsample = 5\n",
    "\n",
    "# field(s) to be weighted \n",
    "fields = ['rank']\n",
    "\n",
    "# strength of weights (-ve to downweight)\n",
    "exponents = [2]\n",
    "\n",
    "# arguments for twint\n",
    "kwargs = {'n_retries':2,\n",
    "         'suppress':False}\n",
    "\n",
    "# package pagerank parameters into tuple\n",
    "pagerank_params = nodelist, edgelist, graph\n",
    "\n",
    "# run boosting, now would be a good time to make a cup of tea\n",
    "gdb.boost_graph(niter,nsample,fields,exponents,pagerank_params,keyword,kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D5: Filter by Topic and keyword\n",
    "\n",
    "### D.5.1 Filter graph by keywords\n",
    "\n",
    "Look for keywords in the bio and screen name of friends, filter users who have these keywords.\n",
    "\n",
    "This is a brute force approach to identifying users associated with a topic. It can used in conjunction with or instead of the topic modelling. For example, one may select the list of key words based on analysing hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['tech','security','artificial','machine', 'cyber', 'computer','code','hack']\n",
    "not_techies = gdb.filter_users_by_keywords(keywords,graph,without=True)\n",
    "print(len(not_techies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excise uninteresting profiles\n",
    "gdb.excise_outliers(not_techies['screen name'],graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.5.2 Filter by topic\n",
    "\n",
    "Use the results of the topic modelling to get a list a users who tweet about a given topic regularly. Users who don't regularly tweet about this topic can be excised from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of users who DO talk about a topic\n",
    "topic = 'Cybersecurity'\n",
    "topical = gdb.filter_by_topic(topic,graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at a few entries\n",
    "print(topical[:10])\n",
    "print(len(topical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of users who DON'T talk about this topic\n",
    "untopical = users_df[~users_df['screen_name'].isin(topical['screen_name'])]['screen_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at a few entries\n",
    "print(untopical[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excise untopical users\n",
    "gdb.excise_outliers(untopical,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.5.3 Run Page Rank again\n",
    "\n",
    "Run page rank again to get ranking within topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Page rank using follower edges\n",
    "print('running page rank')\n",
    "nodelist = ['Person']\n",
    "edgelist = ['FOLLOWS']\n",
    "page_rank = gdb.run_pagerank(nodelist,edgelist,graph,new_native_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_rank[:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
